{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rxMhvIqeoTw"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwrxX75keoTz",
        "outputId": "df077d35-4d9c-4859-b26a-95ab276b49ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/jacklynjoaquin/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/jacklynjoaquin/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os #library in managing directories\n",
        "import re, string #library in removing special characters\n",
        "\n",
        "#for text pre-processing\n",
        "import nltk #natural language tool kit\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "#for model-building\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "#for feature extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TSajVw1eoT0"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVYUD-MVeoT0",
        "outputId": "1c7e413a-4bef-40e4-f00f-2dd7d26dcf7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      id                                               text label  rating\n",
            "0   4715  For a movie that gets no respect there sure ar...   pos       9\n",
            "1  12390  Bizarre horror movie filled with famous faces ...   pos       8\n",
            "2   8329  A solid, if unremarkable film. Matthau, as Ein...   pos       7\n",
            "3   9063  It's a strange feeling to sit alone in a theat...   pos       8\n",
            "4   3092  You probably all already know this by now, but...   pos      10\n",
            "          id                                               text label  rating\n",
            "49995  11513  With actors like Depardieu and Richard it is r...   neg       1\n",
            "49996   5409  If you like to get a couple of fleeting glimps...   neg       1\n",
            "49997  11187  When something can be anything you want it to ...   neg       1\n",
            "49998   9359  I had heard good things about \"States of Grace...   neg       3\n",
            "49999  11556  Well, this movie actually did have one redeemi...   neg       1\n"
          ]
        }
      ],
      "source": [
        "imdb_data = pd.read_csv('/Users/jacklynjoaquin/Documents/IMDB-project/imdb_data_extended.csv')\n",
        "print(imdb_data.head())\n",
        "print(imdb_data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qZwlZJceoT1",
        "outputId": "f7f677c9-8965-4656-ce33-2f0eb9a4f0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id         int64\n",
            "text      object\n",
            "label     object\n",
            "rating     int64\n",
            "dtype: object\n",
            "Data shape:  (50000, 4)\n"
          ]
        }
      ],
      "source": [
        "print(imdb_data.dtypes)\n",
        "print(\"Data shape: \", imdb_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "odTN3wUleoT1",
        "outputId": "a99458ed-4faa-436c-90da-a635d6ace07e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm a fan of Crash and Blade Runner and this movie explores some of those highway death and 80s film noir themes that I like to see, so I enjoyed it.<br /><br />In general though, the essential stupidity of the film noir protagonist is not pulled off well by the female lead and her hero is nearly a neanderthal, hence the kitch warning.\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_data['text'][4000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry_HUrB5eoT1"
      },
      "source": [
        "## Text Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b778Mh_MeoT2",
        "outputId": "3641d68f-6089-40d4-9462-280e745a370e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          id                                               text label  rating   \n",
            "0       4715  For a movie that gets no respect there sure ar...   pos       9  \\\n",
            "1      12390  Bizarre horror movie filled with famous faces ...   pos       8   \n",
            "2       8329  A solid, if unremarkable film. Matthau, as Ein...   pos       7   \n",
            "3       9063  It's a strange feeling to sit alone in a theat...   pos       8   \n",
            "4       3092  You probably all already know this by now, but...   pos      10   \n",
            "...      ...                                                ...   ...     ...   \n",
            "49995  11513  With actors like Depardieu and Richard it is r...   neg       1   \n",
            "49996   5409  If you like to get a couple of fleeting glimps...   neg       1   \n",
            "49997  11187  When something can be anything you want it to ...   neg       1   \n",
            "49998   9359  I had heard good things about \"States of Grace...   neg       3   \n",
            "49999  11556  Well, this movie actually did have one redeemi...   neg       1   \n",
            "\n",
            "                                               processed  \n",
            "0      [For, a, movie, that, gets, no, respect, there...  \n",
            "1      [Bizarre, horror, movie, filled, with, famous,...  \n",
            "2      [A, solid, ,, if, unremarkable, film, ., Matth...  \n",
            "3      [It, 's, a, strange, feeling, to, sit, alone, ...  \n",
            "4      [You, probably, all, already, know, this, by, ...  \n",
            "...                                                  ...  \n",
            "49995  [With, actors, like, Depardieu, and, Richard, ...  \n",
            "49996  [If, you, like, to, get, a, couple, of, fleeti...  \n",
            "49997  [When, something, can, be, anything, you, want...  \n",
            "49998  [I, had, heard, good, things, about, ``, State...  \n",
            "49999  [Well, ,, this, movie, actually, did, have, on...  \n",
            "\n",
            "[50000 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# text tokenizing\n",
        "imdb_data['processed'] = imdb_data['text'].apply(lambda x: nltk.word_tokenize(x))\n",
        "print(imdb_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_GH_ZVMeoT2",
        "outputId": "c19c1f33-f220-4bec-ae57-de9975db5348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      id                                               text label  rating   \n",
            "0   4715  For a movie that gets no respect there sure ar...   pos       9  \\\n",
            "1  12390  Bizarre horror movie filled with famous faces ...   pos       8   \n",
            "2   8329  A solid, if unremarkable film. Matthau, as Ein...   pos       7   \n",
            "3   9063  It's a strange feeling to sit alone in a theat...   pos       8   \n",
            "4   3092  You probably all already know this by now, but...   pos      10   \n",
            "\n",
            "                                           processed  \n",
            "0  movie gets respect sure lot memorable quotes l...  \n",
            "1  bizarre horror movie filled famous faces stole...  \n",
            "2  solid unremarkable film matthau einstein wonde...  \n",
            "3  strange feeling sit alone theater occupied par...  \n",
            "4  probably already know additional episodes neve...             id                                               text label  rating   \n",
            "49995  11513  With actors like Depardieu and Richard it is r...   neg       1  \\\n",
            "49996   5409  If you like to get a couple of fleeting glimps...   neg       1   \n",
            "49997  11187  When something can be anything you want it to ...   neg       1   \n",
            "49998   9359  I had heard good things about \"States of Grace...   neg       3   \n",
            "49999  11556  Well, this movie actually did have one redeemi...   neg       1   \n",
            "\n",
            "                                               processed  \n",
            "49995  actors like depardieu richard really hard task...  \n",
            "49996  like get couple fleeting glimpses cleavage att...  \n",
            "49997  something anything want mean bound register so...  \n",
            "49998  heard good things states grace came open mind ...  \n",
            "49999  well movie actually one redeeming quality made...  \n"
          ]
        }
      ],
      "source": [
        "#stop word, white space, special character removal, contraction expansion, lowercase transformation\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "new_stopwords = [\"would\",\"shall\",\"could\",\"might\", 'br']\n",
        "stop_words.extend(new_stopwords)\n",
        "stop_words.remove(\"not\")\n",
        "stop_words = set(stop_words)\n",
        "\n",
        "def remove_special_char(text):\n",
        "    clean_text = re.sub(r'[^a-zA-Z\\s]','', text)\n",
        "    return clean_text\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    clean_data = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop_words and i.strip().lower().isalpha():\n",
        "            clean_data.append(i.strip().lower())\n",
        "    return \" \".join(clean_data)\n",
        "\n",
        "def expand_contractions(text):\n",
        "    contractions_dict = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"don't\": \"do not\" }\n",
        "\n",
        "    # Regular expression pattern to find contractions\n",
        "    contractions_pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b')\n",
        "\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "\n",
        "    # Use regular expression to find and replace contractions\n",
        "    expanded_text = contractions_pattern.sub(replace, text)\n",
        "\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        "def data_cleaning(text):\n",
        "    text = expand_contractions(text)\n",
        "    text = remove_special_char(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "imdb_data['processed'] = imdb_data['processed'].apply(lambda x: ' '.join(x))\n",
        "imdb_data['processed'] = imdb_data['processed'].apply(lambda x: data_cleaning(x))\n",
        "print(imdb_data.head(), imdb_data.tail())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9iVej5heoT4"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZeiv9t0eoT4",
        "outputId": "4dbbb9ba-dd8e-46dd-d2b0-d33184361ac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17967    not long jeff jarrett left wwf good spoke nigh...\n",
            "32391    loved movie since saw theater wil wheaton favo...\n",
            "9341     compromised fairly charming film liked art dir...\n",
            "7929     ralph bakshi films appear like twoedged swords...\n",
            "46544    roger corman non epic sundry bunch characters ...\n",
            "                               ...                        \n",
            "21243    another fine effort america underrated filmmak...\n",
            "45891    word honor erased vocabularies nations aggrava...\n",
            "42613    found movie complete waste minutes jones weird...\n",
            "43567    must rate worst films ever seen nt funny wife ...\n",
            "2732     not film entertaining excellent comedic acting...\n",
            "Name: processed, Length: 35000, dtype: object\n"
          ]
        }
      ],
      "source": [
        "#train-test set split\n",
        "X_train, X_test, y_train, y_test = train_test_split(imdb_data['processed'], imdb_data['label'], test_size=0.3, random_state=0, shuffle=True)\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "peCMmD23E-28"
      },
      "outputs": [],
      "source": [
        "# TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True, min_df=5)\n",
        "X_train_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_vectors = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpdocLJTIysd",
        "outputId": "5d0cd9b1-3b8c-42da-8941-c210a4bd8f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aa' 'angel' 'baking' 'bobs' 'capes' 'cliffhanger' 'cope' 'decent'\n",
            " 'distract' 'emanuelle' 'fahrenheit' 'founders' 'gotcha' 'helicopters'\n",
            " 'impatience' 'jacks' 'largely' 'mack' 'mikey' 'nearly' 'ossie' 'phat'\n",
            " 'process' 'recounting' 'roaring' 'secrets' 'skinner' 'staking' 'swedish'\n",
            " 'tonight' 'unforgivable' 'wardrobe' 'yugoslavian']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "32122"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(tfidf_vectorizer.get_feature_names_out()[::1000])\n",
        "len(tfidf_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsity of the Bi-gram matrix: 0.9971\n"
          ]
        }
      ],
      "source": [
        "# Calculate sparsity\n",
        "total_elements = X_train_vectors.shape[0] * X_train_vectors.shape[1]\n",
        "non_zero_elements = X_train_vectors.nnz\n",
        "sparsity = 1 - (non_zero_elements / total_elements)\n",
        "\n",
        "print(f\"Sparsity of the Bi-gram matrix: {sparsity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SelectKBest for Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aaa', 'aag', 'aaliyah', 'aames', 'aamir', 'aardman', 'aaron', 'ab', 'abandoned', 'abandoning', 'abandons', 'abba', 'abbas', 'abbie', 'abbot', 'abbreviated', 'abc', 'abducted', 'abe', 'abel']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(35000, 20000)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_selector = SelectKBest(chi2, k=20000)\n",
        "\n",
        "X_train_vectors_tfidf = feature_selector.fit_transform(X_train_vectors, y_train)\n",
        "X_test_vectors_tfidf = feature_selector.transform(X_test_vectors)\n",
        "\n",
        "selected_feature_indices = feature_selector.get_support(indices=True)\n",
        "selected_features = [feature_names[i] for i in selected_feature_indices]\n",
        "print(selected_features[:20])\n",
        "X_train_vectors_tfidf.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TF-IDF feature importance with Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1qhO50eFC4_",
        "outputId": "8ead3ffd-8867-4f73-9676-c49645f84474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8921333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.90      0.88      0.89      7485\n",
            "         pos       0.88      0.91      0.89      7515\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic regression on TF-IDF\n",
        "lgr = LogisticRegression()\n",
        "lgr.fit(X_train_vectors_tfidf,y_train)\n",
        "\n",
        "y_pred = lgr.predict(X_test_vectors_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IGLTbDZUlpU"
      },
      "source": [
        "## TF-IDF feature importance on Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JzUpGRiMmhi",
        "outputId": "d7fa938f-9797-4b2a-de16-3c625060ab74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7270666666666666\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.58      0.68      7485\n",
            "         pos       0.68      0.87      0.76      7515\n",
            "\n",
            "    accuracy                           0.73     15000\n",
            "   macro avg       0.75      0.73      0.72     15000\n",
            "weighted avg       0.75      0.73      0.72     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "d_tree = DecisionTreeClassifier(max_depth=10)\n",
        "d_tree.fit(X_train_vectors_tfidf,y_train)\n",
        "\n",
        "y_pred = d_tree.predict(X_test_vectors_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhVmQoXMV6vS"
      },
      "source": [
        "## TF-IDF feature importance on Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwR4BYXbV6KS",
        "outputId": "5c27f480-f9c2-4d04-b5d2-7ea2ffe101d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8544\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.85      0.86      0.86      7485\n",
            "         pos       0.86      0.85      0.85      7515\n",
            "\n",
            "    accuracy                           0.85     15000\n",
            "   macro avg       0.85      0.85      0.85     15000\n",
            "weighted avg       0.85      0.85      0.85     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rcf = RandomForestClassifier()\n",
        "rcf.fit(X_train_vectors_tfidf,y_train)\n",
        "\n",
        "y_pred = rcf.predict(X_test_vectors_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwjA3qXBTTqi"
      },
      "source": [
        "## TF-IDF feature importance on Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM1Rxq-YXAS9",
        "outputId": "1421592a-1afd-4fe5-8a0d-5a1081da62f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8642666666666666\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.86      0.87      0.87      7485\n",
            "         pos       0.87      0.86      0.86      7515\n",
            "\n",
            "    accuracy                           0.86     15000\n",
            "   macro avg       0.86      0.86      0.86     15000\n",
            "weighted avg       0.86      0.86      0.86     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_vectors_tfidf,y_train)\n",
        "\n",
        "y_pred = mnb.predict(X_test_vectors_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "minimal_ds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
