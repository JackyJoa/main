{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rxMhvIqeoTw"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwrxX75keoTz",
        "outputId": "ba224823-dca0-4ed6-ab8f-b8db7feb8158"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/jacklynjoaquin/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/jacklynjoaquin/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os #library in managing directories\n",
        "\n",
        "#for text pre-processing\n",
        "import nltk #natural language tool kit\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re, string #library in removing special characters\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Data visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#word embedding\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "#train-test, models, metrics\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TSajVw1eoT0"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVYUD-MVeoT0",
        "outputId": "b6743648-a615-4ba2-914a-eb9a9a9a3fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      id                                               text label  rating\n",
            "0   4715  For a movie that gets no respect there sure ar...   pos       9\n",
            "1  12390  Bizarre horror movie filled with famous faces ...   pos       8\n",
            "2   8329  A solid, if unremarkable film. Matthau, as Ein...   pos       7\n",
            "3   9063  It's a strange feeling to sit alone in a theat...   pos       8\n",
            "4   3092  You probably all already know this by now, but...   pos      10\n",
            "          id                                               text label  rating\n",
            "49995  11513  With actors like Depardieu and Richard it is r...   neg       1\n",
            "49996   5409  If you like to get a couple of fleeting glimps...   neg       1\n",
            "49997  11187  When something can be anything you want it to ...   neg       1\n",
            "49998   9359  I had heard good things about \"States of Grace...   neg       3\n",
            "49999  11556  Well, this movie actually did have one redeemi...   neg       1\n"
          ]
        }
      ],
      "source": [
        "imdb_data = pd.read_csv('/Users/jacklynjoaquin/Documents/IMDB-project/imdb_data_extended.csv')\n",
        "print(imdb_data.head())\n",
        "print(imdb_data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qZwlZJceoT1",
        "outputId": "becca74d-9e1c-4afc-c084-f70e5a1b8082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id         int64\n",
            "text      object\n",
            "label     object\n",
            "rating     int64\n",
            "dtype: object\n",
            "Data shape:  (50000, 4)\n"
          ]
        }
      ],
      "source": [
        "print(imdb_data.dtypes)\n",
        "print(\"Data shape: \", imdb_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "odTN3wUleoT1",
        "outputId": "e2440e64-6ad5-4e39-aebf-fabe2bc7c910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm a fan of Crash and Blade Runner and this movie explores some of those highway death and 80s film noir themes that I like to see, so I enjoyed it.<br /><br />In general though, the essential stupidity of the film noir protagonist is not pulled off well by the female lead and her hero is nearly a neanderthal, hence the kitch warning.\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_data['text'][4000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoDqnrtcqMLK",
        "outputId": "c3959bb0-bea1-4a42-d5a7-3a5eb6c83eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          id                                               text label  rating   \n",
            "0       4715  For a movie that gets no respect there sure ar...   pos       9  \\\n",
            "1      12390  Bizarre horror movie filled with famous faces ...   pos       8   \n",
            "2       8329  A solid, if unremarkable film. Matthau, as Ein...   pos       7   \n",
            "3       9063  It's a strange feeling to sit alone in a theat...   pos       8   \n",
            "4       3092  You probably all already know this by now, but...   pos      10   \n",
            "...      ...                                                ...   ...     ...   \n",
            "49995  11513  With actors like Depardieu and Richard it is r...   neg       1   \n",
            "49996   5409  If you like to get a couple of fleeting glimps...   neg       1   \n",
            "49997  11187  When something can be anything you want it to ...   neg       1   \n",
            "49998   9359  I had heard good things about \"States of Grace...   neg       3   \n",
            "49999  11556  Well, this movie actually did have one redeemi...   neg       1   \n",
            "\n",
            "                                               processed  \n",
            "0      [For, a, movie, that, gets, no, respect, there...  \n",
            "1      [Bizarre, horror, movie, filled, with, famous,...  \n",
            "2      [A, solid, ,, if, unremarkable, film, ., Matth...  \n",
            "3      [It, 's, a, strange, feeling, to, sit, alone, ...  \n",
            "4      [You, probably, all, already, know, this, by, ...  \n",
            "...                                                  ...  \n",
            "49995  [With, actors, like, Depardieu, and, Richard, ...  \n",
            "49996  [If, you, like, to, get, a, couple, of, fleeti...  \n",
            "49997  [When, something, can, be, anything, you, want...  \n",
            "49998  [I, had, heard, good, things, about, ``, State...  \n",
            "49999  [Well, ,, this, movie, actually, did, have, on...  \n",
            "\n",
            "[50000 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#text tokenizing\n",
        "imdb_data['processed'] = imdb_data['text'].apply(lambda x: nltk.word_tokenize(x))\n",
        "print(imdb_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_GH_ZVMeoT2",
        "outputId": "f9004052-a844-450c-a191-5de7e6481259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      id                                               text label  rating   \n",
            "0   4715  For a movie that gets no respect there sure ar...   pos       9  \\\n",
            "1  12390  Bizarre horror movie filled with famous faces ...   pos       8   \n",
            "2   8329  A solid, if unremarkable film. Matthau, as Ein...   pos       7   \n",
            "3   9063  It's a strange feeling to sit alone in a theat...   pos       8   \n",
            "4   3092  You probably all already know this by now, but...   pos      10   \n",
            "\n",
            "                                           processed  \n",
            "0  movie gets respect sure lot memorable quotes l...  \n",
            "1  bizarre horror movie filled famous faces stole...  \n",
            "2  solid unremarkable film matthau einstein wonde...  \n",
            "3  strange feeling sit alone theater occupied par...  \n",
            "4  probably already know additional episodes neve...             id                                               text label  rating   \n",
            "49995  11513  With actors like Depardieu and Richard it is r...   neg       1  \\\n",
            "49996   5409  If you like to get a couple of fleeting glimps...   neg       1   \n",
            "49997  11187  When something can be anything you want it to ...   neg       1   \n",
            "49998   9359  I had heard good things about \"States of Grace...   neg       3   \n",
            "49999  11556  Well, this movie actually did have one redeemi...   neg       1   \n",
            "\n",
            "                                               processed  \n",
            "49995  actors like depardieu richard really hard task...  \n",
            "49996  like get couple fleeting glimpses cleavage att...  \n",
            "49997  something anything want mean bound register so...  \n",
            "49998  heard good things states grace came open mind ...  \n",
            "49999  well movie actually one redeeming quality made...  \n"
          ]
        }
      ],
      "source": [
        "#stop word, white space, special character removal, contraction expansion, lowercase transformation\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "new_stopwords = [\"would\",\"shall\",\"could\",\"might\", 'br']\n",
        "stop_words.extend(new_stopwords)\n",
        "stop_words.remove(\"not\")\n",
        "stop_words = set(stop_words)\n",
        "\n",
        "def remove_special_char(text):\n",
        "    clean_text = re.sub(r'[^a-zA-Z\\s]','', text)\n",
        "    return clean_text\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    clean_data = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop_words and i.strip().lower().isalpha():\n",
        "            clean_data.append(i.strip().lower())\n",
        "    return \" \".join(clean_data)\n",
        "\n",
        "def expand_contractions(text):\n",
        "    contractions_dict = {\n",
        "    \"ain't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"don't\": \"do not\" }\n",
        "\n",
        "    # Regular expression pattern to find contractions\n",
        "    contractions_pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b')\n",
        "\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "\n",
        "    # Use regular expression to find and replace contractions\n",
        "    expanded_text = contractions_pattern.sub(replace, text)\n",
        "\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        "def data_cleaning(text):\n",
        "    text = expand_contractions(text)\n",
        "    text = remove_special_char(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "imdb_data['processed'] = imdb_data['processed'].apply(lambda x: ' '.join(x))\n",
        "imdb_data['processed'] = imdb_data['processed'].apply(lambda x: data_cleaning(x))\n",
        "print(imdb_data.head(), imdb_data.tail())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7_MJbqn2PwK"
      },
      "source": [
        " ## Word2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEgeI8u32YDq",
        "outputId": "6f54b192-c10f-4716-e9d7-6d12dac51169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          id                                               text label  rating   \n",
            "0       4715  For a movie that gets no respect there sure ar...   pos       9  \\\n",
            "1      12390  Bizarre horror movie filled with famous faces ...   pos       8   \n",
            "2       8329  A solid, if unremarkable film. Matthau, as Ein...   pos       7   \n",
            "3       9063  It's a strange feeling to sit alone in a theat...   pos       8   \n",
            "4       3092  You probably all already know this by now, but...   pos      10   \n",
            "...      ...                                                ...   ...     ...   \n",
            "49995  11513  With actors like Depardieu and Richard it is r...   neg       1   \n",
            "49996   5409  If you like to get a couple of fleeting glimps...   neg       1   \n",
            "49997  11187  When something can be anything you want it to ...   neg       1   \n",
            "49998   9359  I had heard good things about \"States of Grace...   neg       3   \n",
            "49999  11556  Well, this movie actually did have one redeemi...   neg       1   \n",
            "\n",
            "                                               processed  \n",
            "0      [movie, gets, respect, sure, lot, memorable, q...  \n",
            "1      [bizarre, horror, movie, filled, famous, faces...  \n",
            "2      [solid, unremarkable, film, matthau, einstein,...  \n",
            "3      [strange, feeling, sit, alone, theater, occupi...  \n",
            "4      [probably, already, know, additional, episodes...  \n",
            "...                                                  ...  \n",
            "49995  [actors, like, depardieu, richard, really, har...  \n",
            "49996  [like, get, couple, fleeting, glimpses, cleava...  \n",
            "49997  [something, anything, want, mean, bound, regis...  \n",
            "49998  [heard, good, things, states, grace, came, ope...  \n",
            "49999  [well, movie, actually, one, redeeming, qualit...  \n",
            "\n",
            "[50000 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#text tokenizing\n",
        "imdb_data['processed'] = imdb_data['processed'].apply(lambda x: nltk.word_tokenize(x))\n",
        "print(imdb_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ja7YFpUx2NvW"
      },
      "outputs": [],
      "source": [
        "#Tokenized sentences should be in a list, where each element is a list of words.\n",
        "tokenized_sentences = imdb_data['processed'].tolist()\n",
        "\n",
        "#Train Word2Vec model\n",
        "model = Word2Vec(tokenized_sentences, vector_size=300, window=5, min_count=1, sg=0)\n",
        "\n",
        "#Save model for later use\n",
        "model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiStOPDSO_jq",
        "outputId": "a8b67982-adfa-404b-a081-9eb77098cc19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec<vocab=133868, vector_size=300, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding similar words from Word2Vec features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDKkXK4dsnFd",
        "outputId": "34d7cc74-e57a-4a95-f034-5a29a9cf9ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('actor', 0.7976747751235962), ('role', 0.6875707507133484), ('performance', 0.6593881845474243)]\n"
          ]
        }
      ],
      "source": [
        "similar_words = model.wv.most_similar(positive=['actress'], topn=3)\n",
        "print(similar_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate word similarity from Word2Vec features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFxqLojspWkg",
        "outputId": "a4c524c9-614b-41a5-c754-6a079963e12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between given words: 0.68029356\n"
          ]
        }
      ],
      "source": [
        "#calculate similarity\n",
        "similarity_score = model.wv.similarity(\"grass\", \"trees\")\n",
        "print(\"Similarity between given words:\", similarity_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "m_OneCr43ro0"
      },
      "outputs": [],
      "source": [
        "#Transform tokenized data to feature vectors using Word2Vec model\n",
        "X = []\n",
        "for sentence in tokenized_sentences:\n",
        "    sentence_vector = [model.wv[word] for word in sentence if word in model.wv]\n",
        "    if sentence_vector:  #Skip empty sentences\n",
        "        sentence_vector = sum(sentence_vector)  #Combine word vectors in a sentence\n",
        "        X.append(sentence_vector)\n",
        "\n",
        "#Prepare labels (y) and split data into train-test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, imdb_data['label'], test_size=0.3, random_state=0, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word2Vec features on Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsqE-Qe7R9j9",
        "outputId": "d5b6b8c2-340e-4c61-d61b-21dcd2453923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.801\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.81      0.79      0.80      7485\n",
            "         pos       0.79      0.81      0.80      7515\n",
            "\n",
            "    accuracy                           0.80     15000\n",
            "   macro avg       0.80      0.80      0.80     15000\n",
            "weighted avg       0.80      0.80      0.80     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word2Vec features on Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnG8TW5Z5HLT",
        "outputId": "8da72ad8-3514-4e76-9d37-cce10fb3945f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jacklynjoaquin/miniconda3/envs/minimal_ds/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8437333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.85      0.84      0.84      7485\n",
            "         pos       0.84      0.85      0.84      7515\n",
            "\n",
            "    accuracy                           0.84     15000\n",
            "   macro avg       0.84      0.84      0.84     15000\n",
            "weighted avg       0.84      0.84      0.84     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "logR = LogisticRegression()\n",
        "logR.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logR.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word2Vec features on Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch9mp3f4ZMcM",
        "outputId": "9470180d-3f7b-4ea2-c671-0c612cf23ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6971333333333334\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.70      0.70      0.70      7485\n",
            "         pos       0.70      0.70      0.70      7515\n",
            "\n",
            "    accuracy                           0.70     15000\n",
            "   macro avg       0.70      0.70      0.70     15000\n",
            "weighted avg       0.70      0.70      0.70     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "#cross-validation on training data\n",
        "scores = cross_val_score(decision_tree, X_train, y_train, cv=5)\n",
        "\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word2Vec features on Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SRO00Hw_hGzh"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
        "\n",
        "scaler = MinMaxScaler() #preprocess data - normalizing it to range 0 to 1 - removing the negative numbers.\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK97irk85SJk",
        "outputId": "fb719a8f-efbe-4197-e516-bf80b470f780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6724666666666667\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.71      0.59      0.64      7485\n",
            "         pos       0.65      0.75      0.70      7515\n",
            "\n",
            "    accuracy                           0.67     15000\n",
            "   macro avg       0.68      0.67      0.67     15000\n",
            "weighted avg       0.68      0.67      0.67     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train, y_train)\n",
        "\n",
        "#cross-validation on training data\n",
        "scores = cross_val_score(mnb, X_train, y_train, cv=5)\n",
        "\n",
        "y_pred = mnb.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "minimal_ds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
